---
- name: Deploy softwares docker and environment on all instances
  hosts: master
  remote_user: ubuntu
  become: yes
  gather_facts: true
  vars_files: vars/vm_settings.yml

  tasks:
    - name: Set up the environment for Spark
      lineinfile:
        path: ~/.bashrc 
        line: "export PATH = $PATH:/usr/local/spark/bin"
        state: present

    - name: sourcing the ~/.bashrc file.
      become: no   
      shell: . ~/.bashrc 
      args:
        executable: /bin/bash

    - name: Edit spark-env.sh
      command: cp spark-env.sh.template spark-env.sh
      args:
        chdir: /usr/local/spark/conf

    - name: edit the configuration file spark-env.sh
      lineinfile:
        path: /usr/local/spark/conf/spark-env.sh
        line: '{{ item }}'
        state: present
      with_items:
          - "export SPARK_MASTER_HOST='{{ master_IP }}'"
          - "export JAVA_HOME=/usr/bin/java"

    - name: Edit the configuration file slaves
      lineinfile:
        path: /usr/local/spark/conf/slaves.template
        line: '{{ item }}'
        state: present
      with_items:
        - "master"
        - "slave01"
        - "slave02"
        - "slave03"
    
    - name: Installs ssh
      apt:
        name: ['openssh-server', 'openssh-client']
        state: latest

    - name: start spark
      shell: ./sbin/start-all.sh
      args:
        chdir: /usr/local/spark